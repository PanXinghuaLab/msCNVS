# 遍历all_query1中剩余的查询
for(i in 2:length(all_query1)){
# 获取与当前查询相关的文献ID
new_query=get_pubmed_ids(all_query1[i])
# 检查是否有相关文献
if(new_query$Count!=0){
# 根据获取的ID，从PubMed中提取相关文献信息
fetched_data=fetch_pubmed_data(new_query, encoding = "ASCII")
# 将提取的文献数据整理成一个数据框，以作者为单位进行归类
new_PM_df=table_articles_byAuth(pubmed_data = fetched_data,
included_authors = "first",
max_chars = 0,
encoding = "ASCII")
# 创建一个新列'name'，包含作者的姓氏及其他信息
new_PM_df['name']=paste(new_PM_df$lastname,'et al',new_PM_df$jabbrv)
# 选择特定的列（DOI、姓名、年份、标题）构成最终的数据框
new_PM_df=new_PM_df[,c('doi','name','year','title')]
colnames(new_PM_df)<-c('DOI', 'Name', 'Year', 'Title')
# 将新提取的数据追加到原始数据框中
organs_PM_df=rbind(organs_PM_df,new_PM_df)}
}
all_query[[i]]=paste("(",i,")"," ","AND"," ","(",data_t,")",sep="")}
library(easyPubMed)
##关键词设置##
organs=c('Lung','nose','pharynx','larynx','trachea','bronchi','alveolar','COVID-19','SARS','flu')
data_t=c('scRNA-seq','scATAC-seq','snRNA-seq')
for(i in organs){
all_query[[i]]=paste("(",i,")"," ","AND"," ","(",data_t,")",sep="")}
all_query=list()
for(i in organs){
all_query[[i]]=paste("(",i,")"," ","AND"," ","(",data_t,")",sep="")}
all_queryl=unlist（all_query）###转变为向量
all_query1 = unlist(all_query)###转变为向量
all_query1
all_query1
#从PubMed中获取与all_query1［1］相关的文献ID
new_query=get_pubmed_ids(all_query1[1])
fetched_data=fetch_pubmed_data(new_query, encoding = "ASCII")
# 将提取的文献数据整理成一个数据框，以作者为单位进行归类
organs_PM_df=table_articles_byAuth(pubmed_data = fetched_data,
included_authors = "first",
max_chars = 0,
encoding = "ASCII")
# 创建一个新列'name'，包含作者的姓氏及其他信息
organs_PM_df ['name']=paste(organs_PM_df$lastname, 'et al' ,organs_PM_df$jabbrv)
# 选择特定的列（DOI、姓名、年份、标题）构成最终的数据框
organs_PM_df=organs_PM_df[,c('doi', 'name', 'year','title')]
# 重命名数据框的列名
colnames (organs_PM_df)=c('DOI', 'Name', 'Year', 'Title')
# 遍历all_query1中剩余的查询
for(i in 2:length(all_query1)){
# 获取与当前查询相关的文献ID
new_query=get_pubmed_ids(all_query1[i])
# 检查是否有相关文献
if(new_query$Count. =0){
# 遍历all_query1中剩余的查询
for(i in 2:length(all_query1)){
# 获取与当前查询相关的文献ID
new_query=get_pubmed_ids(all_query1[i])
# 检查是否有相关文献
if(new_query$Count!=0){
# 根据获取的ID，MPubMed中提取相关文献信息
fetched_data=fetch_pubmed_data(new_query, encoding = "ASCII")
# 将提取的文献数据整理成一个数据框，以作者为单位进行归类
new_PM_df=table_articles_byAuth (pubmed_data = fetched_data,
included_authors = "first",
max_chars = 0,
encoding = "ASCII")
# 创建一个新列'name'，包含作者的姓氏及其他信息
new_PM_df ['name ' ]=paste(new_PM_df$lastname, 'et al',new_PM_df$jabbrv)
#选择特定的列（DOI、姓名、年份、标题）构成最终的数据框
new_PM_df=new_PM_df[, c('doi', 'name' , 'year' , 'title')]
colnames (new_PM_df) <-c('DOI', 'Name', 'Year', 'Title')
# 将新提取的数据追加到原始数据框中
organs_PM_df=rbind (organs_PM_df,new_PM_df)
}
}
all_query1
i
# 获取与当前查询相关的文献ID
new_query=get_pubmed_ids(all_query1[i])
# 检查是否有相关文献
if(new_query$Count!=0){
# 根据获取的ID，MPubMed中提取相关文献信息
fetched_data=fetch_pubmed_data(new_query, encoding = "ASCII")
# 将提取的文献数据整理成一个数据框，以作者为单位进行归类
new_PM_df=table_articles_byAuth (pubmed_data = fetched_data,
included_authors = "first",
max_chars = 0,
encoding = "ASCII")
# 创建一个新列'name'，包含作者的姓氏及其他信息
new_PM_df ['name ' ]=paste(new_PM_df$lastname, 'et al',new_PM_df$jabbrv)
#选择特定的列（DOI、姓名、年份、标题）构成最终的数据框
new_PM_df=new_PM_df[, c('doi', 'name' , 'year' , 'title')]
colnames (new_PM_df) <-c('DOI', 'Name', 'Year', 'Title')
# 将新提取的数据追加到原始数据框中
organs_PM_df=rbind (organs_PM_df,new_PM_df)
}
new_query
new_query$Count!=0
# 根据获取的ID，MPubMed中提取相关文献信息
fetched_data=fetch_pubmed_data(new_query, encoding = "ASCII")
# 将提取的文献数据整理成一个数据框，以作者为单位进行归类
new_PM_df=table_articles_byAuth (pubmed_data = fetched_data,
included_authors = "first",
max_chars = 0,
encoding = "ASCII")
# 创建一个新列'name'，包含作者的姓氏及其他信息
new_PM_df ['name']=paste(new_PM_df$lastname, 'et al',new_PM_df$jabbrv)
#选择特定的列（DOI、姓名、年份、标题）构成最终的数据框
new_PM_df=new_PM_df[, c('doi', 'name' , 'year' , 'title')]
colnames (new_PM_df) <-c('DOI', 'Name', 'Year', 'Title')
# 将新提取的数据追加到原始数据框中
organs_PM_df=rbind (organs_PM_df,new_PM_df)
# 检查是否有相关文献
if(new_query$Count!=0){
# 根据获取的ID，MPubMed中提取相关文献信息
fetched_data=fetch_pubmed_data(new_query, encoding = "ASCII")
# 将提取的文献数据整理成一个数据框，以作者为单位进行归类
new_PM_df=table_articles_byAuth (pubmed_data = fetched_data,
included_authors = "first",
max_chars = 0,
encoding = "ASCII")
# 创建一个新列'name'，包含作者的姓氏及其他信息
new_PM_df ['name']=paste(new_PM_df$lastname, 'et al',new_PM_df$jabbrv)
#选择特定的列（DOI、姓名、年份、标题）构成最终的数据框
new_PM_df=new_PM_df[, c('doi', 'name' , 'year' , 'title')]
colnames (new_PM_df) <-c('DOI', 'Name', 'Year', 'Title')
# 将新提取的数据追加到原始数据框中
organs_PM_df=rbind (organs_PM_df,new_PM_df)
}
# 遍历all_query1中剩余的查询
for(i in 2:length(all_query1)){
# 获取与当前查询相关的文献ID
new_query=get_pubmed_ids(all_query1[i])
# 检查是否有相关文献
if(new_query$Count!=0){
# 根据获取的ID，MPubMed中提取相关文献信息
fetched_data=fetch_pubmed_data(new_query, encoding = "ASCII")
# 将提取的文献数据整理成一个数据框，以作者为单位进行归类
new_PM_df=table_articles_byAuth (pubmed_data = fetched_data,
included_authors = "first",
max_chars = 0,
encoding = "ASCII")
# 创建一个新列'name'，包含作者的姓氏及其他信息
new_PM_df ['name']=paste(new_PM_df$lastname, 'et al',new_PM_df$jabbrv)
#选择特定的列（DOI、姓名、年份、标题）构成最终的数据框
new_PM_df=new_PM_df[, c('doi', 'name' , 'year' , 'title')]
colnames (new_PM_df) <-c('DOI', 'Name', 'Year', 'Title')
# 将新提取的数据追加到原始数据框中
organs_PM_df=rbind (organs_PM_df,new_PM_df)
}
}
library(easyPubMed)
rm(list())
rm(list = ls())
library(easyPubMed)
##关键词设置##
organs=c('Lung','nose','pharynx','larynx','trachea','bronchi','alveolar','COVID-19','SARS','flu')
data_t=c('scRNA-seq','scATAC-seq','snRNA-seq')
all_query=list()
for(i in organs){
all_query[[i]]=paste("(",i,")"," ","AND"," ","(",data_t,")",sep="")}
all_query[[i]]
##关键词设置##
organs=c('Lung','nose','pharynx','larynx','trachea','bronchi','alveolar','COVID-19','SARS','flu')[c(1:2)]
data_t=c('scRNA-seq','scATAC-seq','snRNA-seq')[c(1:2)]
all_query=list()
for(i in organs){
all_query[[i]]=paste("(",i,")"," ","AND"," ","(",data_t,")",sep="")}
# ---------------------------------------------------------------------------
all_query1 = unlist(all_query)###转变为向量
all_query1
#从PubMed中获取与all_query1［1］相关的文献ID
new_query=get_pubmed_ids(all_query1[1])
all_query1[1]
View(new_query)
fetched_data=fetch_pubmed_data(new_query, encoding = "ASCII")
# 将提取的文献数据整理成一个数据框，以作者为单位进行归类
organs_PM_df=table_articles_byAuth(pubmed_data = fetched_data,
included_authors = "first",
max_chars = 0,
encoding = "ASCII")
View(organs_PM_df)
View(organs_PM_df)
# 创建一个新列'name'，包含作者的姓氏及其他信息
organs_PM_df ['name']=paste(organs_PM_df$lastname, 'et al' ,organs_PM_df$jabbrv)
# 选择特定的列（DOI、姓名、年份、标题）构成最终的数据框
organs_PM_df=organs_PM_df[,c('doi', 'name', 'year','title')]
# 重命名数据框的列名
colnames (organs_PM_df)=c('DOI', 'Name', 'Year', 'Title')
View(new_query)
View(organs_PM_df)
library(Seurat)
library(Seurat)
install.packages("Seurat")
install.packages("Seurat")
install.packages("sceasy")
install.packages("R.utils")
library(Seurat)
x <- readRDS("~/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_hPSC_fetal_lung_cells.rds")
library("Seurat")
library("sceasy")
library("R.utils")
library("Seurat")
library("sceasy")
install.packages("sceasy")
library("Seurat")
library("sceasy")
library("Seurat")
library("sceasy")
library("Seurat")
library("sceasy")
library("R.utils")
x <- readRDS("~/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_hPSC_fetal_lung_cells.rds")
install.packages("BiocManager")
BiocManager::valid()
BiocManager::install("sceasy")
library("Seurat")
library("sceasy")
BiocManager::install("sceasy")
devtools::install_github("cellgeni/sceasy")
install.packages("devtools")
devtools::install_github("cellgeni/sceasy")
library("Seurat")
library("sceasy")
library("R.utils")
x <- readRDS("~/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_hPSC_fetal_lung_cells.rds")
sceasy::convertFormat(x,from="seurat",to="anndata",outFile='GSE266789_SeuratObject.h5ad',main_layer = "data",transfer_layers = 'counts')
library(reticulate)
# 指定 Python 环境（dataflow 环境）
use_condaenv("dataflow", required = TRUE)
# 导入 Python 的 sceasy
sceasy <- import("sceasy")
sceasy::convertFormat(x,from="seurat",to="anndata",outFile='GSE266789_SeuratObject.h5ad',main_layer = "data",transfer_layers = 'counts')
library("Seurat")
library("sceasy")
library("R.utils")
x <- readRDS("~/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_hPSC_fetal_lung_cells.rds")
# 加载必要的 R 包
library(Seurat)
library(reticulate)
# 读取 Seurat 对象
x <- readRDS("~/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_hPSC_fetal_lung_cells.rds")
# 指定 Python 环境（包含 sceasy 的环境）
use_condaenv("dataflow", required = TRUE)
# 导入 Python 的 sceasy
sceasy <- import("sceasy")
# 将 Seurat 对象转换为 AnnData 并保存为 h5ad 文件
sceasy$convert(
from = "seurat",
to = "anndata",
file_path = "GSE266789_SeuratObject.h5ad",
main_layer = "data",
transfer_layers = list("counts")   # Python 需要 list 格式
)
# 将 Seurat 对象转换为 AnnData 并保存为 h5ad 文件
sceasy::convertFormat(
from = "seurat",
to = "anndata",
file_path = "GSE266789_SeuratObject.h5ad",
main_layer = "data",
transfer_layers = list("counts")   # Python 需要 list 格式
)
library("Seurat")
library("sceasy")
library("R.utils")
x <- readRDS("~/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_hPSC_fetal_lung_cells.rds")
sceasy::convertFormat(x,from="seurat",to="anndata",outFile='GSE266789_SeuratObject.h5ad',main_layer = "data",transfer_layers = 'counts')
sceasy::convertFormat(x,
from="seurat",
to="anndata",
outFile='~/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_SeuratObject.h5ad',
main_layer = "data",
transfer_layers = 'counts')
sceasy::convertFormat(x,
from="seurat",
to="anndata",
outFile='~/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_SeuratObject.h5ad',
main_layer = "data",
transfer_layers = 'counts')
sceasy::convertFormat(x,
from="seurat",
to="anndata",
outFile='~/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_SeuratObject.h5ad',
main_layer = "data",
transfer_layers = 'counts')
sceasy::convertFormat(x,
from="seurat",
to="anndata",
outFile='/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_SeuratObject.h5ad',
main_layer = "data",
transfer_layers = 'counts')
sceasy::convertFormat(x,
from="seurat",
to="anndata",
outFile='/Users/XuMengchang/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_SeuratObject.h5ad',
main_layer = "data",
transfer_layers = 'counts')
sceasy::convertFormat(x,
from="seurat",
to="anndata",
outFile='/Users/XuMengchang/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_hPSC_fetal_lung_cells.h5ad',
main_layer = "data",
transfer_layers = 'counts')
x <- readRDS("~/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_hPSC_fetal_lung_organoids.rds")
# 指定 Python 环境（dataflow 环境）
use_condaenv("dataflow", required = TRUE)
sceasy::convertFormat(x,
from="seurat",
to="anndata",
outFile='/Users/XuMengchang/Downloads/10.1038_s41467-024-50281-5/raw/GSE266789_hPSC_fetal_lung_organoids.h5ad',
main_layer = "data",
transfer_layers = 'counts')
a <- readRDS("/home/xmc/data/airway_data_ST/10.1101_2025.10.01.679697_1/raw/raw1/GSE286085_RAW/GSM8717512_xenium_AgedHG3_subset_res0.8_label.rds")
a <- readRDS("~/Desktop/Code/ST/10.1101_2025.10.01.679697_1/raw/GSE286085_RAW/GSM8717512_xenium_AgedHG3_subset_res0.8_label.rds")
View(a)
class(a)
xem <- a
plotVisium(xem,
annotate="subsets_gs_sum",
zoom=TRUE, facets=NULL) +
ggtitle("Xenium")
library(RANN)
library(scater)
BiocManager::install("scater")
library(RANN)
library(scater)
library(RANN)
library(scater)
plotVisium(xem,
annotate="subsets_gs_sum",
zoom=TRUE, facets=NULL) +
ggtitle("Xenium")
library(RANN)
library(scater)
View(xem)
rm(xem)
obj <- a
rm(a)
class(obj)
obj
Assays(obj)
Images(obj)              # Seurat 提供的 accessor（推荐）
obj@images$fov
library(Seurat)
library(Seurat)
names(obj@images)
fov <- obj@images$fov
class(fov)
fov
coords <- GetTissueCoordinates(obj, image = "fov")
coords <- GetTissueCoordinates(fov)
fov <- obj@images$fov
class(fov)
slotNames(fov)
str(fov, max.level = 2)
# 看看 fov 里有哪些名字（如果是 list-like 对象会有）
try(names(fov), silent = TRUE)
# 在 slots 里找可能的坐标/centroid/transcript/segmentation
sn <- slotNames(fov)
sn
# 例：如果存在 coordinates
coords <- slot(fov, "coordinates")
# 例：如果存在 coordinates
coords <- slot(fov, "centroids")
for (s in slotNames(fov)) {
cat("\n--- SLOT:", s, "---\n")
obj_s <- try(slot(fov, s), silent = TRUE)
if (inherits(obj_s, "try-error")) next
print(class(obj_s))
print(utils::head(obj_s))
}
library(SeuratObject)
library(Seurat)
library(SeuratObject)
library(Seurat)
coords <- GetTissueCoordinates(obj, image = "fov")
head(coords)
ImageDimPlot(obj, fov = "fov", molecules = c("Gad1", "Sst", "Pvalb", "Gfap"), nmols = 20000)
# fov 在 obj@images$fov
fov <- obj@images$fov
cent_obj <- slot(fov, "boundaries")$centroids
cent_df <- try(as.data.frame(cent_obj), silent = TRUE)
if (inherits(cent_df, "try-error")) cent_df <- as.data.frame(as.matrix(cent_obj))
cent_df$cell_id <- rownames(cent_df)
# 只保留最核心 3 列：cell_id, x, y
cent_df <- cent_df[, c("cell_id", "x", "y")]
head(cent_df)
history
fov <- obj@images$fov
cent_obj <- slot(fov, "boundaries")$centroids
View(cent_obj)
cent_df <- as.data.frame(cent_obj)
# 细胞 obs（等价于 anndata.obs）
obs <- obj@meta.data
dim(obs)
head(obs)
colnames(obs)
md <- obj@meta.data
# 找和面积相关的列
area_cols <- grep("area", colnames(md), ignore.case = TRUE, value = TRUE)
area_cols
# 只取 nucleus_area / cell_area 等
md_area <- md[, area_cols, drop = FALSE]
head(md_area)
morph_cols <- grep("cell|nucleus|area|perimeter|axis|eccentric|circular|solidity",
colnames(md), ignore.case = TRUE, value = TRUE)
morph_cols
head(md[, morph_cols, drop = FALSE])
fov <- obj@images$fov
seg <- slot(fov, "boundaries")$segmentation
class(seg)
slotNames(seg)
seg_md <- slot(seg, "sf.data")   # 或 seg@data
seg_md <- slot(seg, "sf.data")   # 或 seg@data
seg_md <- slot(seg, "sf.data")
seg
View(seg)
seg_md <- seg@polygons@data   # segmentation 的属性表（obs）
# seg 可能是 list，也可能是 Segmentation
seg0 <- slot(obj@images$fov, "boundaries")$segmentation
seg1 <- if (is.list(seg0)) seg0[[1]] else seg0   # 常见就是第 1 个
# 取 segmentation 对应的属性表（obs-like）
sp <- slot(seg1, "polygons")          # SpatialPolygonsDataFrame
seg_md <- slot(sp, "data")            # 等价于 sp@data
library(SeuratObject)
md <- obj@meta.data
# 看看有哪些疑似面积字段
grep("area|Area|cell_area|nucleus_area|cellarea|nucleus", colnames(md), value = TRUE)
# 如果找到了，比如 nucleus_area / cell_area
head(md[, grep("area|Area", colnames(md), value = TRUE), drop = FALSE])
View(md)
fov <- obj@images$fov
bnd <- slot(fov, "boundaries")
View(bnd)
bnd[["centroids"]]@coords
View(obj)
library(devtools)
library(usethis)
library(rJava)###java环境变量配置
devtools::install_github("PanXinghuaLab/msCNVS")
devtools::install_github("PanXinghuaLab/msCNVS")
setwd("/Users/XuMengchang/Desktop/Code/msCNVS")
# 安装源码（会自动编译/安装）
install.packages(".", repos = NULL, type = "source")
a <- CNVision(dir = "~/Desktop/Code/k562_2_9.bam")
library(CNVision)
a <- CNVision(dir = "~/Desktop/Code/k562_2_9.bam")
a <- CNVision(dir = "~/Desktop/Code/")
b <- LoadBins(a,resolution = 600,length = 150,
genome = "hg19")
c <- CountRead(b)
d <- Maskbins(c,mask_types =c("centromere", "clone",
"contig", "heterochromatin",
"scaffold", "short_arm"))
apply(d@cnvData$bincount, 2, median)
e <- NormalizeData(d,method = "Normalize")
f <- Segment(e,alpha=alpha,undo.splits = "sdundo", nperm=1000, undo.SD=1, min.width=5)
f <- Segment(e,alpha=0.1,undo.splits = "sdundo", nperm=1000, undo.SD=1, min.width=5)
g <- InferPloidy(f,
m_start = 1.5, m_end = 2.5, m_step = 0.1,
b_start = -0.2, b_end = 0.2, b_step = 0.01)
g@result$ploidy
cell = g@config$cells[1]
PlotPloidy(g,cell)
h <- detect_peaks(g,peakHeightThreshold = peakHeightThreshold,plot = T,adjust = adjust,minpeakdistance = 0.3)
set.seed(123)
